deque automatically discards oldest messages when full → acts like a rolling buffer.
Using a lock ensures thread-safety
If your cache is large enough, most polls never hit the database.

from collections import deque
from threading import Lock

MAX_CACHE_SIZE = 1000  # max messages to keep in memory
message_cache = deque(maxlen=MAX_CACHE_SIZE)
cache_lock = Lock()

------- When a new message is created: append it to the cache immediately.
def add_message_to_cache(msg):
    with cache_lock:
        message_cache.append(msg)

---- Each client gets only the messages they haven’t received yet.
the_last_message_seen_by_users = {}
-- this is a dictionary
id -> index in cache
(periodinally clean for inactive clients)


@app.get("/messages", response_model=list[MessageOut])
def get_messages(client_id):
    with cache_lock:
        start_index = the_last_message_seen_by_users.get(client_id, 0)
        new_messages = list(message_cache)[start_index:]
        the_last_message_seen_by_users[client_id] = len(message_cache)
        return new_messages

-------------

On startup: load last N messages from DB.
............ consider Redis?

__________________

the Lock is used to prevent concurrent access to shared data, and with is a convenient Python construct that handles entering and exiting contexts, like acquiring and releasing the lock.

If one thread is inside a with lock: block, other threads trying to acquire the same lock will wait until it’s released.

This prevents race conditions, e.g., two threads appending to message_cache at the same time, which could corrupt the deque.

with is a context manager in Python:

It ensures that resources are cleaned up properly when the block ends, even if an exception occurs.

For locks, it means: automatically acquire at the start and release at the end.
-----------------------------

lock.acquire()
try:
    counter += 1
finally:
    lock.release()

------------------------------

Two clients could poll /messages at the same time.

Both could try to read/modify message_cache or client_last_seen.

Using Lock ensures one request at a time modifies the shared structures, avoiding corruption or inconsistent reads.

